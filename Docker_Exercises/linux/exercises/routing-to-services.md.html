<html>
<head>
    <title>routing-to-services.md</title>
    <link href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css' rel='stylesheet' integrity='sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u' crossorigin='anonymous'>
    <link href="../../app.css" rel="stylesheet" >
</head>
<body>
    <nav class="navbar navbar-default">
    <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><img class="logo" src="https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg" alt="Docker" title="Docker"/></a>
        </div>
    </div><!-- /.container-fluid -->
    </nav>
    <div class="container">
    <div class="row">
        <div class="content">
            <h1 id="routing-to-services">Routing to Services</h1>
<p>By the end of this exercise, you should be able to:</p>
<ul>
<li>Route traffic originating either inside or outside your cluster to stateless Swarm services.</li>
</ul>
<h2 id="routing-cluster-internal-traffic">Routing Cluster-Internal Traffic</h2>
<ol>
<li><p>By <em>cluster-internal traffic</em>, we mean traffic from originating from a container running on your swarm, sending a request to another container running on the same swarm. Let&#39;s create a stack with two such services, attached to a custom overlay network; create a file <code>net-demo.yaml</code> with the following content:</p>
<pre><code class="lang-yaml">version: &quot;3.7&quot;    

services:
  destination:
    image: training/whoami:latest
    deploy:
      replicas: 3
    networks:
      - demonet

  origin:
    image: centos:7
    command: [&quot;sleep&quot;, &quot;100000&quot;]
    networks:
      - demonet          

networks:
  demonet:
    driver: overlay
</code></pre>
<p>Here our <code>destination</code> service is using the <code>deploy:replicas</code> key to ask for three replica containers based on the <code>training/whoami</code> image; this image serves a simple web page on port 8000 that reports the ID of the container its running in. Our <code>origin</code> service is using the <code>command</code> key to define what process to run in a container based on the <code>centos:7</code> image. </p>
</li>
<li><p>Deploy your stack, and find out what node your <code>origin</code> container is running on:</p>
<pre><code class="lang-bash">[centos@node-0 ~]$ docker stack deploy -c net-demo.yaml netstack

[centos@node-0 ~]$ docker stack ps netstack

ID                  NAME                     IMAGE                    NODE
tqsurlytrruu        netstack_destination.1   training/whoami:latest   node-0
lp3hwp3c4nih        netstack_origin.1        centos:7                 node-3
g94q730kdto5        netstack_destination.2   training/whoami:latest   node-1                         
n5297tisleso        netstack_destination.3   training/whoami:latest   node-2
</code></pre>
</li>
<li><p>Switch to the node running your <code>origin</code> container (<code>node-3</code> in the example above), and create a bash shell inside that container:</p>
<pre><code class="lang-bash">[centos@node-3 ~]$ docker container ls

CONTAINER ID        IMAGE               COMMAND       
3047dbb47a7a        centos:7            &quot;sleep 100000&quot;

[centos@node-3 ~]$ docker container exec -it &lt;container ID&gt; bash

[root@3047dbb47a7a /]#
</code></pre>
</li>
<li><p>From within your origin container, attempt to <code>curl</code> your destination container by service name several times:</p>
<pre><code class="lang-bash">[root@3047dbb47a7a /]# curl destination:8000
I&#39;m a16b6e9741db
[root@3047dbb47a7a /]# curl destination:8000
I&#39;m d3d800059d7b
[root@3047dbb47a7a /]# curl destination:8000
I&#39;m bace80287419
[root@3047dbb47a7a /]# curl destination:8000
I&#39;m a16b6e9741db
</code></pre>
<p><em>The service name defined in you stack file is DNS resolvable</em>, and load balances traffic in round robin fashion across all the containers corresponding to that service. In this way, your application logic (simply <code>curl</code> in this example) doesn&#39;t need to do any explicit service discovery or routing to contact another service; all of that is handled by Docker&#39;s networking layer.</p>
</li>
<li><p>(Optional): Still inside your <code>centos</code> container, install <code>nslookup</code>, and use it to see what <code>destination</code> is actually resolving to:</p>
<pre><code class="lang-bash">[root@3047dbb47a7a /]# yum install -y bind-utils

[root@3047dbb47a7a /]# nslookup destination
Server:     127.0.0.11
Address:    127.0.0.11#53    

Non-authoritative answer:
Name:   destination
Address: 10.85.5.133
</code></pre>
<p>That IP (<code>10.85.5.133</code>) is the <em>virtual IP</em> of your <code>destination</code> service. Docker automatically configures an IP virtual server on every host in your Swarm to route traffic from this VIP to the corresponding backend containers as we saw above.</p>
</li>
<li><p>Exit your container, and clean up by removing your stack:</p>
<pre><code class="lang-bash">[root@3047dbb47a7a /]# exit
[centos@node-0 ~]$ docker stack rm netstack
</code></pre>
</li>
</ol>
<h2 id="routing-cluster-external-traffic">Routing Cluster-External Traffic</h2>
<p>In the last section, we routed traffic from one Docker service to another, all within the same swarm. If we want to route ingress traffic from an external network to a service, we have to expose it on the <em>routing mesh</em>.</p>
<ol>
<li><p>Create a new stack file <code>mesh.yaml</code>:</p>
<pre><code class="lang-yaml">version: &quot;3.7&quot;    

services:
  destination:
    image: training/whoami:latest
    deploy:
      replicas: 3
    ports:
      - 8080:8000
</code></pre>
<p>Here the <code>ports:</code> key is specifying that traffic arriving at port 8080 on <em>any node in the swarm</em> should be forwarded to port 8000 of our <code>whoami</code> container.</p>
</li>
<li><p>Deploy your stack, and curl the public IP of any node in your swarm on port 8080 a few times:</p>
<pre><code class="lang-bash">[centos@node-0 ~]$ docker stack deploy -c mesh.yaml mesh

[centos@node-0 ~]$ curl 52.55.221.133:8080
I&#39;m 17f79606a85b
[centos@node-0 ~]$ curl 52.55.221.133:8080
I&#39;m a8f60ac476b9
[centos@node-0 ~]$ curl 52.55.221.133:8080
I&#39;m b285c54f5fb0
[centos@node-0 ~]$ curl 52.55.221.133:8080
I&#39;m 17f79606a85b
</code></pre>
<p>Traffic is forwarded from the host&#39;s network namespace&#39;s port 8080 to the <code>whoami</code> containers&#39; network namespaces in round robin fashion, similarly to above, but this time from <em>outside</em> our swarm; try visiting this IP and port in your browser to convince yourself this is externally reachable (but note that many browsers&#39; caching behavior will hide the round robin load balancing; if you want to see the load balancing in the browser, try using a &#39;history-less&#39; browser mode, closing and reopening the browser or completely purging history between each refresh).</p>
</li>
<li><p>Try the same <code>curl</code> again, but with the public IP for a different node in your swarm; it&#39;ll work the exact same way, since the routing mesh forwards traffic inbound to port 8080 on <em>any</em> node in the swarm on to the containers scheduled for your <code>destination</code> service.</p>
<blockquote>
<p><strong>Cluster internal versus cluster external routing</strong> is often misunderstood by new Swarm users; note that the port mapping <code>8080:8000</code> we created to make our service available externally on the mesh net was <em>not necessary</em> for making our service reachable by other services internally to our swarm. In general, you should not expose services on the mesh net unless they need to be reachable on the external network.</p>
</blockquote>
</li>
<li><p>Clean up by deleting your <code>mesh</code> stack.</p>
</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>In this exercise, you saw the basic service discovery and routing that Swarm enables via DNS lookup of service names, VIP routing and port forwarding across network namespaces. In general, using this networking plane to do our service discovery helps make our inter-service communication more robust against container failure. If we were communicating with a container directly by its IP, we would have to constantly monitor whether that container was still actually reachable at that IP; Swarm effectively does that for us when we communicate via DNS resolution of service names to VIPs, since a failed container will get pulled out of the virtual IP server&#39;s round-robin routing automatically. In the case of using the mesh net to route ingress traffic from outside our cluster, mapping the external port on <em>every</em> host in the swarm onto the service&#39;s VIP means our external load balancers (which is realistically the point of ingress for external traffic to our swarm), doesn&#39;t need to know anything about where our service is scheduled; it can simply send requests to any node in the swarm, and Docker handles the rest.</p>

        </div>        
    </div>
    <div class="row">
        <ul class="mt-article-pagination" style="display:block;">
        </ul>
    </div>
</div>
    <div class="footer"></div>
</body>